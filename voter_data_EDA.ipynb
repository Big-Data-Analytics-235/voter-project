{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf6be9b-0834-4de2-90d5-017d672f0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"gs://voter-project-25-235/VM2Uniform--WY--2021-01-13/VM2Uniform--WY--2021-01-13.tab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d2fd61-0ef4-412a-aea0-2c9a9e47cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "wy_data = spark.read.format(\"csv\")\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".option(\"delimiter\", \"\\t\")\\\n",
    ".csv(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a210055b-71e9-4b4b-b1ce-b58abcaa7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = wy_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45817546-2e82-43ef-9496-2aff92dab566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when\n",
    "def drop_null_columns(df, return_dropped_names = False, threshold = 0):\n",
    "    \"\"\"\n",
    "    Function that drops the columns of a dataframe that contain with only a low number of non-null values.\n",
    "    This number is specified by `threshold`. `threshold = 0` means columns with entirely null values get dropped.\n",
    "    Optionally returns a list of column names that get dropped.\n",
    "    \"\"\"\n",
    "    not_null_cnt = df.select([count(when(col(c).isNotNull(), c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "    to_drop = [k for k, v in not_null_cnt.items() if v <= threshold]\n",
    "    if return_dropped_names:\n",
    "        return df.drop(*to_drop), to_drop\n",
    "    else:\n",
    "        return df.drop(*to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96e068fe-e804-4946-ae09-e0515cfae9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "wy, d_cols = drop_null_columns(wy_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a4545bd-4694-4e45-96fe-17e15fe8488c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0033b-2067-4be9-9f84-e75a1dd822f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}