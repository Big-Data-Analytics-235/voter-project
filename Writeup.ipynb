{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b28054-4af3-4738-b79c-dd228e99c35f",
   "metadata": {},
   "source": [
    "# Analysis of Voter Turnout in Indiana Pre- and Post- Voter Identification Law\n",
    "### Authors: Christopher Lefrak, Hannah Li, George Yang, and Kuai Yu\n",
    "### PSTAT 235\n",
    "\n",
    "NOTES/TO-DO:\n",
    "- truncate/limit outputs so the writeup looks polished and professional (no raw outputs/errors)\n",
    "- interpret findings\n",
    "- include visualizations and graphs (EDA? theoretical concepts?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821a2d3b-0c12-4ebc-a7db-91ad51fefd29",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "[importance/potential effect of voter ID law]\n",
    "\n",
    "Thirty-five of the fifty states of the U.S. have passed stricter voter ID laws that require or request voters to present a form of identification at the polls. \n",
    "The remaining fifteen states do not require voters to present any documentation to vote at the polls. States such as Indiana, Wisconsin, and Tennessee have strict photo ID laws for voters, while states such as Minnesota, Nebraska, North Carolina, and Pennsylvania have no requirements for voter identification. A visualization of the levels of strictness of voter photo identification laws for each state can be seen in the graphic below.\n",
    "\n",
    "![Voter ID Laws](GCS/voteridmap.png)\n",
    "\n",
    "Advantages of implementing stricter voter identification requirements include preventing voter impersonation, thus  increasing public confidence in election processes. Disadvantages of implementing stricter laws unnecessarily burdens voters and administrators.\n",
    "\n",
    "## Goals\n",
    "In this project we focus our investigations of voter identification laws on the state of Indiana, which implemented a strict voter identification law in 2008. We seek to analyze how much voter turnout would have decreased or increased without the implentation of the law. \n",
    "\n",
    "> Project Goals\n",
    "> - Apply the matching method on pre- voter identification law features.\n",
    "> - Conduct k-Nearest-Neighbors (k-NN) classification to make predictions on voter data and cross validation to evaluate.\n",
    "> - Strengthen our pyspark data analysis skills, collaborative skills, and project organization skills\n",
    "\n",
    "[technologies, packages, skills...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ff4d48-f0d5-44ff-ad6c-638ef44b5a47",
   "metadata": {},
   "source": [
    "## Indiana Voter Data\n",
    "\n",
    "### Dataset Overview\n",
    "\n",
    "Our data is from the course's voter files folder. We primarily use the dataset corresponding to Indiana. At a glance, the dataset contains 726 columns and 946908 rows, records beginning from .... and ending at March 5, 2021\n",
    "\n",
    "[eda/visualizations]\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "Many of the columns of the dataset have missing values.\n",
    "We narrowed down our focus to individuals who were of the legal voting age of 18 or older at the time of voting.\n",
    "\n",
    "\n",
    "We subsetted the dataset to focus on a narrower set of voter attributes. We selected the following columns from the original dataset:\n",
    "\n",
    "[table with column names and descriptions]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450b2d06-21f9-4956-9afb-3a953ee7ccb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/03/17 05:33:11 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "23/03/17 05:33:11 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "23/03/17 05:33:11 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/03/17 05:33:11 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.1.3\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.8.15 (default, Nov 22 2022 08:46:39)\n",
      "Spark context Web UI available at http://mycluster-m.c.pstat135-235.internal:36437\n",
      "Spark context available as 'sc' (master = yarn, app id = application_1679026115533_0004).\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "import seaborn as sns\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "from pyspark.sql.functions import *\n",
    "import random\n",
    "import pyspark\n",
    "from pyspark.shell import spark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Setting up visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e718f24-fe9a-4fbf-9c77-e857aa041696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/17 05:33:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:34:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:34:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:34:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:34:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:35:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:35:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:35:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:35:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:36:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:36:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:36:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "[Stage 0:>                                                          (0 + 0) / 1]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m indi_full \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgs://voter-project-235-25/VM2Uniform--IN--2021-01-15_parq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/readwriter.py:458\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    453\u001b[0m recursiveFileLookup \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursiveFileLookup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema, pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n\u001b[1;32m    455\u001b[0m                recursiveFileLookup\u001b[38;5;241m=\u001b[39mrecursiveFileLookup, modifiedBefore\u001b[38;5;241m=\u001b[39mmodifiedBefore,\n\u001b[1;32m    456\u001b[0m                modifiedAfter\u001b[38;5;241m=\u001b[39mmodifiedAfter)\n\u001b[0;32m--> 458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:1033\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1033\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:1200\u001b[0m, in \u001b[0;36mGatewayConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while sending\u001b[39m\u001b[38;5;124m\"\u001b[39m, e, proto\u001b[38;5;241m.\u001b[39mERROR_ON_SEND)\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1200\u001b[0m     answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   1201\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mstartswith(proto\u001b[38;5;241m.\u001b[39mRETURN_MESSAGE):\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/17 05:36:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:37:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:37:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:37:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:37:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:38:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:38:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:38:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:38:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:39:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:39:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:39:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:39:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:40:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:40:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:40:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:40:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:41:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:41:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:41:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:41:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:42:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:42:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:42:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:42:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:43:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:43:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:43:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:43:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:44:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:44:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:44:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:44:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:45:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:45:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:45:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:45:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:46:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:46:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:46:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:46:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:47:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:47:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:47:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:47:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:48:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:48:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:48:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:48:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:49:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:49:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:49:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:49:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:50:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:50:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:50:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:50:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:51:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:51:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:51:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:51:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:52:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:52:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:52:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:52:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:53:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:53:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:53:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:53:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:54:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:54:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:54:36 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:54:51 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:55:06 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/17 05:55:21 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n"
     ]
    }
   ],
   "source": [
    "indi_full = spark.read.parquet(\"gs://voter-project-235-25/VM2Uniform--IN--2021-01-15_parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50878b-4d74-4144-b57b-869ef5ccd83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "    \"Voters_Gender\",\n",
    "    \"Voters_Age\",\n",
    "    \"Voters_BirthDate\",\n",
    "    \"Residence_Families_HHCount\",\n",
    "    \"Residence_HHGender_Description\",\n",
    "    \"Mailing_Families_HHCount\",\n",
    "    \"Mailing_HHGender_Description\",\n",
    "\n",
    "#   !! voter party affiliation\n",
    "    \"Parties_Description\", \n",
    "    \n",
    "    \"CommercialData_PropertyType\",\n",
    "    \"AddressDistricts_Change_Changed_CD\",\n",
    "    \"AddressDistricts_Change_Changed_SD\",\n",
    "    \"AddressDistricts_Change_Changed_HD\",\n",
    "    \"AddressDistricts_Change_Changed_County\",\n",
    "    \"Residence_Addresses_Density\",\n",
    "    \"CommercialData_EstimatedHHIncome\",\n",
    "    \"CommercialData_ISPSA\",\n",
    "    \"CommercialData_AreaMedianEducationYears\",\n",
    "    \"CommercialData_AreaMedianHousingValue\",\n",
    "    \"CommercialData_MosaicZ4Global\",\n",
    "    \"CommercialData_AreaPcntHHMarriedCoupleNoChild\",\n",
    "    \"CommercialData_AreaPcntHHMarriedCoupleWithChild\",\n",
    "    \"CommercialData_AreaPcntHHSpanishSpeaking\",\n",
    "    \"CommercialData_AreaPcntHHWithChildren\",\n",
    "    \"CommercialData_StateIncomeDecile\",\n",
    "    \"Ethnic_Description\",\n",
    "    \"EthnicGroups_EthnicGroup1Desc\",\n",
    "    \"CommercialData_DwellingType\",\n",
    "    \"CommercialData_PresenceOfChildrenCode\",\n",
    "    \"CommercialData_PresenceOfPremCredCrdInHome\",\n",
    "    \"CommercialData_DonatesToCharityInHome\",\n",
    "    \"CommercialData_DwellingUnitSize\",\n",
    "    \"CommercialData_ComputerOwnerInHome\",\n",
    "    \"CommercialData_DonatesEnvironmentCauseInHome\",\n",
    "    \"CommercialData_Education\",\n",
    "    \"General_2000\",\n",
    "    \"General_2004\",\n",
    "    \"PresidentialPrimary_2000\",\n",
    "    \"PresidentialPrimary_2004\",\n",
    "        \n",
    "#   Outcome variable (indiana law happens in 2005, approved by SCOTUS before presidential election in 2008)\n",
    "    \"General_2008\"\n",
    "]\n",
    "\n",
    "indi = (indi_full\n",
    "        .select(cols_to_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562385eb-ce20-4531-a9b4-136523d766c1",
   "metadata": {},
   "source": [
    "Based on the voter's age, we calculate the date at which they turn eighteen. We create a new variable whose value is the year of the earliest election that the voter could potentially participate in. So, if the date at which they turn eighteen is earlier than November 3rd, we set the value to the year at which they turn eighteen. If the date at which they turn eighteen is later than November 3rd, we set the value to the year of the following election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b98dee-96c2-402b-b2c4-c569ae88d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs_add = 18\n",
    "months_add = 18*12\n",
    "\n",
    "# date of national \n",
    "target_month_day_presidential = \"11-03\"\n",
    "\n",
    "# date of Indiana's presidential primary\n",
    "target_month_day_primary = \"05-03\" \n",
    "\n",
    "indi = indi.withColumn(\"DATE_18\", add_months(to_date(col(\"Voters_BirthDate\"),\"MM/dd/yyyy\"), months_add))\n",
    "indi.select([\"Voters_BirthDate\", \"DATE_18\"]).show(10)\n",
    "indi = indi.dropna(subset = \"Voters_BirthDate\")\n",
    "indi = indi.withColumn(\"YEAR_18\", year(\"DATE_18\"))\n",
    "indi = indi.withColumn(\"comparator_date_presidential\", to_date(concat(col(\"YEAR_18\"), lit(\"-\"), lit(target_month_day_presidential))))\n",
    "indi = indi.withColumn(\"comparator_date_primary\", to_date(concat(col(\"YEAR_18\"), lit(\"-\"), lit(target_month_day_primary))))\n",
    "indi = indi.withColumn(\"YEAR_ELIGIBLE_TO_VOTE_PRESIDENTIAL\", \\\n",
    "                             when(col(\"DATE_18\")<=col(\"comparator_date_presidential\"), col(\"YEAR_18\")) \\\n",
    "                             .otherwise(col(\"YEAR_18\") + 1) \\\n",
    "                            )\n",
    "indi = indi.withColumn(\"YEAR_ELIGIBLE_TO_VOTE_PRIMARY\", \\\n",
    "                             when(col(\"DATE_18\")<=col(\"comparator_date_primary\"), col(\"YEAR_18\")) \\\n",
    "                             .otherwise(col(\"YEAR_18\") + 1) \\\n",
    "                            )\n",
    "\n",
    "# check no missing vals:\n",
    "indi.where(col(\"YEAR_18\").isNull()).select(\"YEAR_18\").show(10)\n",
    "\n",
    "# get rid of rows where the voter was not old enough to vote in the 2008 general election\n",
    "indi = indi.filter(col(\"YEAR_ELIGIBLE_TO_VOTE_PRESIDENTIAL\")<=2008).fillna(\"N\", subset = [\"General_2008\"])\n",
    "\n",
    "# for the 2000 and 2004 general elections, replace with \"N\" IF the person was old enough to vote at the time\n",
    "indi = indi.withColumn(\"General_2000\", \\\n",
    "                      when((col(\"YEAR_ELIGIBLE_TO_VOTE_PRESIDENTIAL\")<= 2004) & \\\n",
    "                           (col(\"General_2000\").isNull()), \"N\") \\\n",
    "                      .otherwise(col(\"General_2000\")) \\\n",
    "                      )\n",
    "\n",
    "indi = indi.withColumn(\"General_2004\", \\\n",
    "                      when((col(\"YEAR_ELIGIBLE_TO_VOTE_PRESIDENTIAL\")<= 2004) & \\\n",
    "                           (col(\"General_2004\").isNull()), \"N\") \\\n",
    "                      .otherwise(col(\"General_2004\")) \\\n",
    "                      )\n",
    "\n",
    "# do the same for the primaries:\n",
    "indi = indi.withColumn(\"PresidentialPrimary_2000\", \\\n",
    "                      when((col(\"YEAR_ELIGIBLE_TO_VOTE_PRIMARY\")<= 2004) & \\\n",
    "                           (col(\"PresidentialPrimary_2000\").isNull()), \"N\") \\\n",
    "                      .otherwise(col(\"PresidentialPrimary_2000\")) \\\n",
    "                      )\n",
    "\n",
    "indi = indi.withColumn(\"PresidentialPrimary_2004\", \\\n",
    "                      when((col(\"YEAR_ELIGIBLE_TO_VOTE_PRIMARY\")<= 2004) & \\\n",
    "                           (col(\"PresidentialPrimary_2004\").isNull()), \"N\") \\\n",
    "                      .otherwise(col(\"PresidentialPrimary_2004\")) \\\n",
    "                      )\n",
    "\n",
    "# make the general voting for 2008 a numeric variable; since we've deleted\n",
    "# everyone who was not eligible to vote, this can be directly calculated with a 1-0.\n",
    "indi = indi.withColumn(\"Voted_General_2008\", when(indi.General_2008 == \"Y\",1).otherwise(0))\n",
    "indi = indi.drop(\"General_2008\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c70f7d0-10ad-4dca-885f-aa3ef77395ce",
   "metadata": {},
   "source": [
    "We begin by obtaining a subset of the dataset to prototype code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074fd787-26dd-4006-a93b-109bc7ef1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleind = indi.sample(True, 0.1, seed = 19480384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311b115-3859-4337-8c56-73cacfcf424d",
   "metadata": {},
   "source": [
    "We then convert the column `CommercialData_EstimatedHHIncome` from type string to type numeric by removing the right-most number, and replacing all symbols \"$\", \"-\", and \"+\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db41cf37-8feb-4f66-aaf2-a8b1bdaa2c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleind = sampleind.withColumn(\"CommercialData_EstimatedHHIncome\", regexp_extract(col(\"CommercialData_EstimatedHHIncome\"), \"(?<=-).*\", 0))\n",
    "\n",
    "sampleind = sampleind.withColumn(\"CommercialData_EstimatedHHIncome\", \\\n",
    "                             regexp_replace('CommercialData_EstimatedHHIncome', \"[\\$,+]\", \"\") \\\n",
    "                            )\n",
    "\n",
    "sampleind = sampleind.withColumn(\"CommercialData_EstimatedHHIncome\",col(\"CommercialData_EstimatedHHIncome\").cast('double'))\n",
    "\n",
    "sampleind.select([\"CommercialData_EstimatedHHIncome\"]).show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb305a3b-c61f-4042-93ee-8fb4e8682d15",
   "metadata": {},
   "source": [
    "We also convert the column `CommercialData_AreaMedianHousingValue` from type string to type numeric by replacing the symbol \"$\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51be547-5be1-45d7-afc3-debae785e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleind = sampleind.withColumn(\"CommercialData_AreaMedianHousingValue\", regexp_replace(\"CommercialData_AreaMedianHousingValue\", \"\\$\", \"\"))\n",
    "sampleind = sampleind.withColumn(\"CommercialData_AreaMedianHousingValue\",col(\"CommercialData_AreaMedianHousingValue\").cast('double'))\n",
    "sampleind.select([\"CommercialData_AreaMedianHousingValue\"]).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29db863-dd0d-4a57-a48d-304e6ca420ab",
   "metadata": {},
   "source": [
    "We proceed to search for the string \"Pnct\" in all of the column names in our dataset, and convert these columns\n",
    "\n",
    "> - 'CommercialData_AreaPcntHHMarriedCoupleNoChild'\n",
    "> - 'CommercialData_AreaPcntHHMarriedCoupleWithChild'\n",
    "> - 'CommercialData_AreaPcntHHSpanishSpeaking'\n",
    "> -'CommercialData_AreaPcntHHWithChildren'\n",
    " \n",
    "to numeric types by replacing the symbol \"%\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1254c-3dd3-4cdb-9d83-16af0219e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_convert = [c for c in sampleind.columns if \"Pcnt\" in c]\n",
    "\n",
    "for col_name in cols_to_convert:\n",
    "    sampleind = sampleind.withColumn(col_name, regexp_replace(col_name, \"\\%\", \"\"))\n",
    "    sampleind = sampleind.withColumn(col_name, col(col_name).cast('double'))\n",
    "    sampleind.select([col_name]).show(5, truncate=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b570a674-34cd-47f9-8fff-22027a86df4d",
   "metadata": {},
   "source": [
    "We then remove the columns that were used for obtaining voter turnout data from our dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a14c2f-3e0f-491a-8d7c-5450500e9527",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"comparator_date_presidential\", \"target_month_day_primary\", \n",
    "                   \"YEAR_ELIGIBLE_TO_VOTE_PRESIDENTIAL\", \"comparator_date_primary\", \n",
    "                   \"YEAR_ELIGIBLE_TO_VOTE_PRIMARY\", \"YEAR_18\", \"DATE_18\"]\n",
    "\n",
    "sampleind = sampleind.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ba59e8-3537-4c35-aee3-5b7a9eee6d88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Regression vs Matching\n",
    "### Regression\n",
    "Regression is parametric as it has a function linking the treatment $D$ and covariates $X$ with the outcome $Y$, and has parameters $\\beta$'s to be estimated\n",
    "\n",
    "\n",
    "#### Problem with regression\n",
    "- doesn’t estimate weight based on weighted average- proportional on variance of the treatment in that group\n",
    "- Assumes linear relationships bt covariates and outcome\n",
    "- Underfitting, underestimating\n",
    "- instead: knn for matching thing\n",
    "\n",
    "### Matching\n",
    "\n",
    "Matching is a statistical technique used to compare treated and non-treated data points with each other to reduce bias and evaluate the effect of the treatment. The matching process entails finding one or more non-treated data points with similar covariates to match a treated data point. In this case, we match voters from pre-voter identification law Indiana, before 2008, to voters from post-voter identification law Indiana, 2008 and beyond. We want to match voters with similar characteristics [column names] in order to predict [....], and, ultimately, to evaluate the effect of the voter identification law on voter turnout in Indiana.\n",
    "\n",
    "Unlike regression, matching is non-parametric as it does not assume a functional form, and does not rely on the assumption of linearity.\n",
    "\n",
    "![Regression vs Matching](GCS/regressionmatching.png)\n",
    "\n",
    "Matching assumes the following:\n",
    "\n",
    "> - Conditional Independence Assumption (CIA): \n",
    ">> - The potential outcomes are independent of the treatment assignment after adjusting for a set of covariates $X$\n",
    ">> - This means that \n",
    "> - Common Support Assumption:\n",
    ">> - There should be untreated and treated observations for each combination of values of covariates $X$ in the data to ensure matches.\n",
    ">> - This means that if the treated group is small relative to the entire dataset, we are more likely to have common support.\n",
    "\n",
    "However, the matching process is not perfect as \"overmatching\" can actually increase bias.\n",
    "\n",
    "Additionally, working with numerous variables (dimensions) can result in the curse of dimensionality. When the number of dimensions of our dataset increases, for example as the number of covariates $X$ grows larger and larger relative to the number of rows in our dataset, we are less likely to find close matches for our treated observations.\n",
    "\n",
    "- Central limit thm doesn’t always hold-> bias correction\n",
    "\n",
    "## Application to Voter Data\n",
    "Variables:\n",
    "> - x: (sex)\n",
    "> - T=treatment assignment under natural circumstances(whether u have a voter - turnout law passed in your state) (drug)\n",
    "> - Y= treatment effect/outcome (voter turnout) (days)\n",
    "> - Y1,Y0= realized outcomes (if u were treated (have laws), if u weren’t treated (no laws))\n",
    "> - Average treatment effect (how much voter turnout would have increased or decreased without law)\n",
    "> - If we have independence bt (Y0,Y1) and T, easy\n",
    "> - If not, must do things including matching\n",
    "\n",
    "We will follow the matching process for voter data from Indiana, then repeat it for another state [state] for comparison.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5762ff81-5d44-4c5d-86ce-26f0a6be2f75",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11734024-a001-421e-85de-a420cf7a5b1e",
   "metadata": {},
   "source": [
    "## Other State Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb77773-514b-4c75-935f-185cd8530507",
   "metadata": {},
   "source": [
    "## k-Nearest-Neighbors (k-NN)\n",
    "\n",
    "We build a k-NN model, which is a supervised machine learning model. Thus, it learns from already labeled data points.\n",
    "- curse of dimensionality\n",
    "### Cross Validation\n",
    "- see how well knn performs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abc2e49-f80b-4ba0-85a2-1b2a0a42e8bc",
   "metadata": {},
   "source": [
    "## Backup: Logistic Regression\n",
    "\n",
    "Logistic regression is a statistical method\n",
    "- use non-indiana data to predict Indiana data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a2c481-e077-4f9d-8692-88cf9d0c097d",
   "metadata": {},
   "source": [
    "## Summary of Findings\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "[summary of everything]\n",
    "\n",
    "[issues - curse of dimensionality]\n",
    "\n",
    "[significance]\n",
    "\n",
    "[possible future work]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac20cc5-b91b-455b-be9e-11990075871c",
   "metadata": {},
   "source": [
    "## Resources\n",
    "https://www.ncsl.org/elections-and-campaigns/voter-id#undefined \n",
    "\n",
    "https://www.franciscoyira.com/post/matching-in-r-2-differences-regression/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63204e4b-8a00-47c5-992b-70d8c4cf06a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}