{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e81c0e0c-3106-46ee-b8e6-c31c0975d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import seaborn as sns\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "from pyspark.sql.functions import *\n",
    "import random\n",
    "\n",
    "# Setting up visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1120f99-3898-4b22-b9e3-d6601058926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "    \"Voters_Gender\", # cat\n",
    "    \"Voters_Age\", # num\n",
    "#    \"Voters_BirthDate\", # ignore\n",
    "    \"Residence_Families_HHCount\", # num\n",
    "    \"Residence_HHGender_Description\", # cat\n",
    "    \"Mailing_Families_HHCount\", # num\n",
    "    \"Mailing_HHGender_Description\", # cat\n",
    "\n",
    "#   !! voter party affiliation\n",
    "    \"Parties_Description\", \n",
    "    \n",
    "    # cat\n",
    "    \"CommercialData_PropertyType\",\n",
    "    \"AddressDistricts_Change_Changed_CD\",\n",
    "    \"AddressDistricts_Change_Changed_SD\",\n",
    "    \"AddressDistricts_Change_Changed_HD\",\n",
    "    \"AddressDistricts_Change_Changed_County\",\n",
    "    \n",
    "    \"Residence_Addresses_Density\", # num\n",
    "    \n",
    "    # cat\n",
    "    \"CommercialData_EstimatedHHIncome\",\n",
    "    \"CommercialData_ISPSA\",\n",
    "#    \"CommercialData_AreaMedianEducationYears\",\n",
    "    \"CommercialData_AreaMedianHousingValue\",\n",
    "    \"CommercialData_MosaicZ4Global\",\n",
    "#     \"CommercialData_AreaPcntHHMarriedCoupleNoChild\",  ## Redundant\n",
    "#     \"CommercialData_AreaPcntHHMarriedCoupleWithChild\",\n",
    "#     \"CommercialData_AreaPcntHHSpanishSpeaking\",\n",
    "#     \"CommercialData_AreaPcntHHWithChildren\",\n",
    "    \"CommercialData_StateIncomeDecile\",\n",
    "#    \"Ethnic_Description\",\n",
    "    \"EthnicGroups_EthnicGroup1Desc\",\n",
    "    \"CommercialData_DwellingType\",\n",
    "    \"CommercialData_PresenceOfChildrenCode\",\n",
    "#    \"CommercialData_PresenceOfPremCredCrdInHome\", ## too many missing\n",
    "    \"CommercialData_DonatesToCharityInHome\",\n",
    "    \"CommercialData_DwellingUnitSize\",\n",
    "    \"CommercialData_ComputerOwnerInHome\",\n",
    "    \"CommercialData_DonatesEnvironmentCauseInHome\",\n",
    "    \"CommercialData_Education\",\n",
    "    \n",
    "#   Don't include because of lookahead bias  \n",
    "#     \"Voters_VotingPerformanceEvenYearGeneral\",\n",
    "#     \"Voters_VotingPerformanceEvenYearPrimary\",\n",
    "#     \"Voters_VotingPerformanceEvenYearGeneralAndPrimary\",\n",
    "#     \"Voters_VotingPerformanceMinorElection\",\n",
    "    \n",
    "#   Other control variables that expect to be highly associated with outcome:\n",
    "#     \"ElectionReturns_P08CountyTurnoutAllRegisteredVoters\",\n",
    "#     \"ElectionReturns_P08CountyTurnoutDemocrats\",\n",
    "#     \"ElectionReturns_P08CountyTurnoutRepublicans\",\n",
    "    \"General_2000\",\n",
    "    \"General_2004\",\n",
    "    \"PresidentialPrimary_2000\",\n",
    "    \"PresidentialPrimary_2004\",\n",
    "        \n",
    "#   Outcome variable (indiana law happens in 2005, approved by SCOTUS before presidential election in 2008)\n",
    "    \"General_2008\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c1b9cbc-1d10-44e3-93a0-649e524540c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VM2Uniform--VT--2021-05-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463261\n",
      "VM2Uniform--IL--2021-03-05: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8336875\n",
      "VM2Uniform--MA--2021-01-19: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4572639\n",
      "VM2Uniform--MD--2021-02-15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4110570\n",
      "VM2Uniform--ME--2021-05-28: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040452\n",
      "root\n",
      " |-- Voters_Gender: string (nullable = true)\n",
      " |-- Voters_Age: string (nullable = true)\n",
      " |-- Residence_Families_HHCount: string (nullable = true)\n",
      " |-- Residence_HHGender_Description: string (nullable = true)\n",
      " |-- Mailing_Families_HHCount: string (nullable = true)\n",
      " |-- Mailing_HHGender_Description: string (nullable = true)\n",
      " |-- Parties_Description: string (nullable = true)\n",
      " |-- CommercialData_PropertyType: string (nullable = true)\n",
      " |-- AddressDistricts_Change_Changed_CD: string (nullable = true)\n",
      " |-- AddressDistricts_Change_Changed_SD: string (nullable = true)\n",
      " |-- AddressDistricts_Change_Changed_HD: string (nullable = true)\n",
      " |-- AddressDistricts_Change_Changed_County: string (nullable = true)\n",
      " |-- Residence_Addresses_Density: string (nullable = true)\n",
      " |-- CommercialData_EstimatedHHIncome: string (nullable = true)\n",
      " |-- CommercialData_ISPSA: string (nullable = true)\n",
      " |-- CommercialData_AreaMedianHousingValue: string (nullable = true)\n",
      " |-- CommercialData_MosaicZ4Global: string (nullable = true)\n",
      " |-- CommercialData_StateIncomeDecile: string (nullable = true)\n",
      " |-- EthnicGroups_EthnicGroup1Desc: string (nullable = true)\n",
      " |-- CommercialData_DwellingType: string (nullable = true)\n",
      " |-- CommercialData_PresenceOfChildrenCode: string (nullable = true)\n",
      " |-- CommercialData_DonatesToCharityInHome: string (nullable = true)\n",
      " |-- CommercialData_DwellingUnitSize: string (nullable = true)\n",
      " |-- CommercialData_ComputerOwnerInHome: string (nullable = true)\n",
      " |-- CommercialData_DonatesEnvironmentCauseInHome: string (nullable = true)\n",
      " |-- CommercialData_Education: string (nullable = true)\n",
      " |-- General_2000: string (nullable = true)\n",
      " |-- General_2004: string (nullable = true)\n",
      " |-- PresidentialPrimary_2000: string (nullable = true)\n",
      " |-- PresidentialPrimary_2004: string (nullable = true)\n",
      " |-- General_2008: string (nullable = true)\n",
      " |-- STATE: string (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "499289"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the states that do not have strict voter ID laws:\n",
    "#  'VM2Uniform--CA--2021-05-02',\tVM2Uniform--CA--2021-05-02\tCA\tx\tCalifornia\n",
    "#  'VM2Uniform--IL--2021-03-05',\tVM2Uniform--IL--2021-03-05\tIL\tx\tIllinois\n",
    "#  'VM2Uniform--MA--2021-01-19',\tVM2Uniform--MA--2021-01-19\tMA\tx\tMassachusetts\n",
    "#  'VM2Uniform--MD--2021-02-15',\tVM2Uniform--MD--2021-02-15\tMD\tx\tMaryland\n",
    "#  'VM2Uniform--ME--2021-05-28',\tVM2Uniform--ME--2021-05-28\tME\tx\tMaine\n",
    "#  'VM2Uniform--MN--2021-02-14',\tVM2Uniform--MN--2021-02-14\tMN\tx\tMinnesota\n",
    "#  'VM2Uniform--NC--2021-05-18',\tVM2Uniform--NC--2021-05-18\tNC\tx\tNorth Carolina\n",
    "#  'VM2Uniform--NE--2021-01-20',\tVM2Uniform--NE--2021-01-20\tNE\tx\tNebraska\n",
    "#  'VM2Uniform--NJ--2021-03-11',\tVM2Uniform--NJ--2021-03-11\tNJ\tx\tNew Jersey\n",
    "#  'VM2Uniform--NM--2021-02-25',\tVM2Uniform--NM--2021-02-25\tNM\tx\tNew Mexico\n",
    "#  'VM2Uniform--NV--2021-06-13',\tVM2Uniform--NV--2021-06-13\tNV\tx\tNevada\n",
    "#  'VM2Uniform--NY--2021-03-15',\tVM2Uniform--NY--2021-03-15\tNY\tx\tNew York\n",
    "#  'VM2Uniform--OR--2021-02-05',\tVM2Uniform--OR--2021-02-05\tOR\tx\tOregon\n",
    "#  'VM2Uniform--PA--2021-05-20',\tVM2Uniform--PA--2021-05-20\tPA\tx\tPennsylvania\n",
    "#  'VM2Uniform--VT--2021-05-28',\tVM2Uniform--VT--2021-05-28\tVT\tx\tVermont\n",
    "\n",
    "# For each of these states, I want to pull enough samples to get a total sample of 1/2 M; can increase later\n",
    "\n",
    "# grab files\n",
    "states =  [\n",
    "# For now, just exclude New York and Califonria, because the parquet files take too long to read\n",
    " 'VM2Uniform--VT--2021-05-28',\n",
    "    \n",
    "    \n",
    "    \n",
    "  'VM2Uniform--IL--2021-03-05',\n",
    "  'VM2Uniform--MA--2021-01-19',\n",
    "  'VM2Uniform--MD--2021-02-15',\n",
    "  'VM2Uniform--ME--2021-05-28',\n",
    "#   'VM2Uniform--MN--2021-02-14',\n",
    "#   'VM2Uniform--NC--2021-05-18',\n",
    "#   'VM2Uniform--NE--2021-01-20',\n",
    "#   'VM2Uniform--NJ--2021-03-11',\n",
    "#   'VM2Uniform--NM--2021-02-25',\n",
    "#   'VM2Uniform--NV--2021-06-13',\n",
    "#   'VM2Uniform--OR--2021-02-05',\n",
    "#   'VM2Uniform--PA--2021-05-20',\n",
    " \n",
    "    \n",
    "     #'VM2Uniform--CA--2021-05-02',\n",
    "\n",
    "     #'VM2Uniform--NY--2021-03-15',\n",
    "\n",
    "]\n",
    "\n",
    "# bucket file path for all state parquet files\n",
    "gcs_path = 'gs://pstat135-voter-file/VM2Uniform'\n",
    "\n",
    "# create list of state abbreviations\n",
    "pattern = re.compile(r\"(?<=--)[A-Z]{2}\")\n",
    "state_abvs = re.findall(pattern, ''.join(states))\n",
    "\n",
    "# do first iteration\n",
    "print('VM2Uniform--VT--2021-05-28')\n",
    "\n",
    "num_per_state = 100000\n",
    "\n",
    "df_ref = spark.read.parquet(\"/\".join([gcs_path, 'VM2Uniform--VT--2021-05-28']))\n",
    "df_ref = df_ref.select(cols_to_keep)\n",
    "\n",
    "numrows = {'VM2Uniform--VT--2021-05-28': df_ref.count()}\n",
    "\n",
    "print(\"%d\" % (numrows['VM2Uniform--VT--2021-05-28']))\n",
    "    \n",
    "percentage_sample = num_per_state / numrows['VM2Uniform--VT--2021-05-28']\n",
    "    \n",
    "df_ref = df_ref.sample(True, percentage_sample, seed = 19480384)\n",
    "df_ref = df_ref.withColumn('STATE', F.lit(state_abvs[0]))\n",
    " \n",
    "next_states = states[1:]\n",
    "\n",
    "# do the rest of the iterations\n",
    "for i, one_state in enumerate(next_states):\n",
    "\n",
    "    print(\"%s: \" % (one_state), end=\"\")\n",
    "    \n",
    "    # read dataframe for one_state\n",
    "    tmp_ref = spark.read.parquet(\"/\".join([gcs_path, one_state]))\n",
    "    tmp_ref = tmp_ref.select(cols_to_keep)\n",
    "    numrows[one_state] = tmp_ref.count()\n",
    "    print(\"%d\" % (numrows[one_state]))\n",
    "    \n",
    "    percentage_sample = num_per_state / numrows[one_state]\n",
    "    \n",
    "    tmp_ref = tmp_ref.sample(True, percentage_sample, seed = 19480384)\n",
    "    tmp_ref = tmp_ref.withColumn('STATE', F.lit(state_abvs[i+1]))\n",
    "    \n",
    "    df_ref = df_ref.union(tmp_ref)      \n",
    "\n",
    "# gcs_path = 'gs://pstat135-voter-file/VM2Uniform'\n",
    "# numrows = dict()\n",
    "# first DF\n",
    "#df_ref = spark.read.parquet('gs://pstat135-voter-file/VM2Uniform/')\n",
    "df_ref.printSchema()\n",
    "df_ref.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef336d8-4729-4341-a01a-7fecc7580962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# others\n",
    "for one_state in states[1:]:\n",
    "    print(\"%s: \" % (one_state), end=\"\")\n",
    "    \n",
    "    # read dataframe for one_state\n",
    "    df = spark.read.parquet(\"/\".join([gcs_path, one_state]))\n",
    "    \n",
    "    # sample small proportion\n",
    "    sample_df = df.sample(True, percentage_sample, seed = 19480384)\n",
    "    \n",
    "    # Then, rbind / concatenate all the files together\n",
    "    df_ref = df_ref.union(sample_df)\n",
    "\n",
    "# Save as parquet into google cloud\n",
    "\n",
    "df_ref.write.format(\"parquet\").save(\"total_reference_sample\")\n",
    "df_ref = spark.read.parquet(\"total_reference_sample\")\n",
    "\n",
    "# Then, run the Indiana file's code on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be71f1d3-acba-4634-a776-6470d8400031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voters_Gender',\n",
       " 'Residence_HHGender_Description',\n",
       " 'Mailing_HHGender_Description',\n",
       " 'Parties_Description',\n",
       " 'CommercialData_PropertyType',\n",
       " 'AddressDistricts_Change_Changed_CD',\n",
       " 'AddressDistricts_Change_Changed_SD',\n",
       " 'AddressDistricts_Change_Changed_HD',\n",
       " 'AddressDistricts_Change_Changed_County',\n",
       " 'CommercialData_EstimatedHHIncome',\n",
       " 'CommercialData_ISPSA',\n",
       " 'CommercialData_AreaMedianHousingValue',\n",
       " 'CommercialData_MosaicZ4Global',\n",
       " 'CommercialData_StateIncomeDecile',\n",
       " 'EthnicGroups_EthnicGroup1Desc',\n",
       " 'CommercialData_DwellingType',\n",
       " 'CommercialData_PresenceOfChildrenCode',\n",
       " 'CommercialData_DonatesToCharityInHome',\n",
       " 'CommercialData_DwellingUnitSize',\n",
       " 'CommercialData_ComputerOwnerInHome',\n",
       " 'CommercialData_DonatesEnvironmentCauseInHome',\n",
       " 'CommercialData_Education',\n",
       " 'General_2000',\n",
       " 'General_2004',\n",
       " 'PresidentialPrimary_2000',\n",
       " 'PresidentialPrimary_2004',\n",
       " 'General_2008',\n",
       " 'STATE']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for categorical variables, replace missing value with \"O\" for \n",
    "# other (including General_2000, General_2004, PresidentialPrimary_2000, PresidentialPrimary_2004)\n",
    "\n",
    "# Get a list of all column types:\n",
    "numeric_cols = [item[0] for item in df_ref.dtypes if not (item[1].startswith('string') or item[1].startswith('date'))]\n",
    "categorical_cols = [item[0] for item in df_ref.dtypes if item[1].startswith('string')]\n",
    "\n",
    "categorical_cols\n",
    "#numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2f7bb56-dcd9-4b44-b085-8081f2721cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-------------------------------------+-------------------------------------+-------------------------------+\n",
      "|CommercialData_DwellingType|CommercialData_PresenceOfChildrenCode|CommercialData_DonatesToCharityInHome|CommercialData_DwellingUnitSize|\n",
      "+---------------------------+-------------------------------------+-------------------------------------+-------------------------------+\n",
      "|       Single Family Dwe...|                 Not Likely to hav...|                                    Y|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                 Not Likely to hav...|                                    Y|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                           Known Data|                                    Y|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                           Known Data|                                    Y|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                           Known Data|                                    U|           1-Single Family D...|\n",
      "|       Multi-Family Dwel...|                 Not Likely to hav...|                                    Y|                           null|\n",
      "|       Single Family Dwe...|                 Not Likely to hav...|                                    U|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                 Modeled Not as Li...|                                    U|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                 Not Likely to hav...|                                    U|           1-Single Family D...|\n",
      "|                       null|                                 null|                                 null|                           null|\n",
      "|       Single Family Dwe...|                           Known Data|                                    Y|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                 Not Likely to hav...|                                    U|           1-Single Family D...|\n",
      "|                       null|                                 null|                                 null|                           null|\n",
      "|       Single Family Dwe...|                 Modeled Not as Li...|                                    U|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                 Not Likely to hav...|                                    Y|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                 Not Likely to hav...|                                    U|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                 Not Likely to hav...|                                    Y|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                 Not Likely to hav...|                                    Y|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                 Modeled Likely to...|                                    U|           1-Single Family D...|\n",
      "|       Single Family Dwe...|                           Known Data|                                    Y|           1-Single Family D...|\n",
      "+---------------------------+-------------------------------------+-------------------------------------+-------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ref.select('CommercialData_DwellingType',\n",
    " 'CommercialData_PresenceOfChildrenCode',\n",
    " 'CommercialData_DonatesToCharityInHome',\n",
    " 'CommercialData_DwellingUnitSize').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1dde8e4a-f869-425b-89cb-9866b4778e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    'Voters_Age',\n",
    "    'Residence_Families_HHCount',\n",
    "    'Mailing_Families_HHCount',\n",
    "    'Residence_Addresses_Density'\n",
    "]\n",
    "\n",
    "trinary_cols = [\n",
    "    'CommercialData_DonatesToCharityInHome',\n",
    "    'CommercialData_ComputerOwnerInHome',\n",
    "    'CommercialData_DonatesEnvironmentCauseInHome'\n",
    "]\n",
    "\n",
    "binary_cols = [\n",
    "    \"General_2000\",\n",
    "    \"General_2004\",\n",
    "    \"PresidentialPrimary_2000\",\n",
    "    \"PresidentialPrimary_2004\"\n",
    "]\n",
    "\n",
    "other_cols = [c for c in df_ref.columns if c != \"General_2008\"]\n",
    "other_cols = [c for c in other_cols if c not in (numeric_cols + trinary_cols + binary_cols)]\n",
    "\n",
    "categorical_cols = other_cols + binary_cols + trinary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7680085e-7c64-472b-953f-05ed26b313c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Voters_Gender: string (nullable = false)\n",
      " |-- Voters_Age: float (nullable = true)\n",
      " |-- Residence_Families_HHCount: float (nullable = true)\n",
      " |-- Residence_HHGender_Description: string (nullable = false)\n",
      " |-- Mailing_Families_HHCount: float (nullable = true)\n",
      " |-- Mailing_HHGender_Description: string (nullable = false)\n",
      " |-- Parties_Description: string (nullable = false)\n",
      " |-- CommercialData_PropertyType: string (nullable = false)\n",
      " |-- AddressDistricts_Change_Changed_CD: string (nullable = false)\n",
      " |-- AddressDistricts_Change_Changed_SD: string (nullable = false)\n",
      " |-- AddressDistricts_Change_Changed_HD: string (nullable = false)\n",
      " |-- AddressDistricts_Change_Changed_County: string (nullable = false)\n",
      " |-- Residence_Addresses_Density: float (nullable = true)\n",
      " |-- CommercialData_EstimatedHHIncome: string (nullable = false)\n",
      " |-- CommercialData_ISPSA: string (nullable = false)\n",
      " |-- CommercialData_AreaMedianHousingValue: string (nullable = false)\n",
      " |-- CommercialData_MosaicZ4Global: string (nullable = false)\n",
      " |-- CommercialData_StateIncomeDecile: string (nullable = false)\n",
      " |-- EthnicGroups_EthnicGroup1Desc: string (nullable = false)\n",
      " |-- CommercialData_DwellingType: string (nullable = false)\n",
      " |-- CommercialData_PresenceOfChildrenCode: string (nullable = false)\n",
      " |-- CommercialData_DonatesToCharityInHome: string (nullable = false)\n",
      " |-- CommercialData_DwellingUnitSize: string (nullable = false)\n",
      " |-- CommercialData_ComputerOwnerInHome: string (nullable = false)\n",
      " |-- CommercialData_DonatesEnvironmentCauseInHome: string (nullable = false)\n",
      " |-- CommercialData_Education: string (nullable = false)\n",
      " |-- General_2000: string (nullable = false)\n",
      " |-- General_2004: string (nullable = false)\n",
      " |-- PresidentialPrimary_2000: string (nullable = false)\n",
      " |-- PresidentialPrimary_2004: string (nullable = false)\n",
      " |-- General_2008: string (nullable = true)\n",
      " |-- STATE: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in numeric_cols:\n",
    "    df_ref = df_ref.withColumn(c, F.col(c).cast(\"float\").alias(c))\n",
    "df_ref = df_ref.fillna(\"U\", subset= trinary_cols)\n",
    "df_ref = df_ref.fillna(\"Missing\", subset = other_cols)\n",
    "df_ref = df_ref.fillna(\"N\", subset = binary_cols)\n",
    "df_ref.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "393b6e99-8b06-4ec1-8be2-c39fb7618c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(31,[0,1,2,3,7,14...|\n",
      "|(31,[0,1,2,3,7,14...|\n",
      "|(31,[0,1,2,3,4,7,...|\n",
      "|(31,[0,1,2,3,4,7,...|\n",
      "|(31,[0,1,2,3,4,7,...|\n",
      "|(31,[0,1,2,3,5,6,...|\n",
      "|(31,[0,1,2,3,4,5,...|\n",
      "|(31,[0,1,2,3,4,7,...|\n",
      "|(31,[0,1,2,3,4,7,...|\n",
      "|(31,[0,1,2,3,4,5,...|\n",
      "|(31,[0,1,2,3,7,13...|\n",
      "|(31,[0,1,2,3,5,6,...|\n",
      "|(31,[0,1,2,3,5,6,...|\n",
      "|(31,[0,1,2,3,5,6,...|\n",
      "|(31,[0,1,2,3,7,13...|\n",
      "|(31,[0,1,2,3,4,5,...|\n",
      "|(31,[0,1,2,3,4,7,...|\n",
      "|(31,[0,1,2,3,7,13...|\n",
      "|(31,[0,1,2,3,5,13...|\n",
      "|(31,[0,1,2,3,5,13...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Create copy of working df\n",
    "new_df = df_ref.alias('new_df')\n",
    "\n",
    "# Impute the missing values in the numerical columns with the mean -- minimize change to z-scores of given data\n",
    "imputer = Imputer(\n",
    "    inputCols=numeric_cols, \n",
    "    outputCols=[\"{}_imputed\".format(c) for c in numeric_cols]\n",
    ")\n",
    "\n",
    "new_df = imputer.fit(new_df).transform(new_df)\n",
    "\n",
    "# Impute categorical columns -- maybe it's better to drop these records\n",
    "# new_df = new_df.fillna(\"missing\", subset = categorical_cols)\n",
    "\n",
    "# Assemble numerical columns into vector\n",
    "vec = VectorAssembler(inputCols = [c+\"_imputed\" for c in numeric_cols], outputCol = \"numFeatures\")\n",
    "new_df = vec.transform(new_df)\n",
    "\n",
    "# Standardize the numeric columns\n",
    "scaler = StandardScaler(inputCol=\"numFeatures\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=True)\n",
    "new_df = scaler.fit(new_df).transform(new_df)\n",
    "\n",
    "# output columns to be indexed\n",
    "indexed_cols = [f\"index{i}\" for i in range(len(categorical_cols))]\n",
    "\n",
    "# Ecode categorical variables\n",
    "indexer = StringIndexer(inputCols = categorical_cols, outputCols = indexed_cols)\n",
    "new_df = indexer.fit(new_df).transform(new_df)\n",
    "\n",
    "# Through categorical variables in their own vector\n",
    "vec = VectorAssembler(inputCols = indexed_cols, outputCol = \"catFeatures\")\n",
    "new_df = vec.transform(new_df)\n",
    "\n",
    "# Concatenate scaled numerical and categorical vectors into single features vector\n",
    "vec = VectorAssembler(inputCols = ['scaledFeatures', 'catFeatures'], outputCol = \"features\")\n",
    "new_df = vec.transform(new_df)\n",
    "\n",
    "new_df.select(\"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c52eace-b368-4108-82e8-07a0c52721a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 200:=====================================================> (34 + 1) / 35]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|General_2004| count|\n",
      "+------------+------+\n",
      "|           Y|162862|\n",
      "|           N|336427|\n",
      "+------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "new_df.groupBy('General_2004').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "316c2446-04f8-428a-bf59-723051460ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "indi_full = spark.read.parquet(\"gs://voter-project-235-25/VM2Uniform--IN--2021-01-15_parq\")\n",
    "indi = indi_full.select('General_2004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7400cf87-b516-4320-8026-eaac0e05621e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 206:==================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|General_2004|  count|\n",
      "+------------+-------+\n",
      "|        null|2734476|\n",
      "|           Y|1662100|\n",
      "+------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indi.groupBy(\"General_2004\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4a261b56-6c2f-415c-830d-591c92e588f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6219558128871194"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2734476/(2734476 + 1662100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb404344-e938-466f-8ef5-e60b3c693af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6738121608927895"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "336427/(162862+336427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ae58c-d486-4c4b-9cbd-2ec0656ddce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}